{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "import torch\n",
    "import Stemmer\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from typing import Any, Dict, Iterator, List, Mapping, Optional\n",
    "from langchain_core.callbacks.manager import CallbackManagerForChainRun\n",
    "from langchain_core.language_models import BaseLanguageModel\n",
    "from langchain_core.prompts import BasePromptTemplate\n",
    "from langchain_community.graphs.networkx_graph import get_entities\n",
    "from langchain.chains import GraphQAChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "import bm25s\n",
    "import heapq\n",
    "import networkx as nx\n",
    "from utils.preprocessing import stemmer, preprocess_text\n",
    "from utils.graph import KGraphPreproc\n",
    "from utils.llm.mistral import MistralLLM\n",
    "from utils.prompt import GRAPH_QA_PROMPT, ENTITY_PROMPT, \\\n",
    "    NO_CONTEXT_PROMPT, EVALUATE_CONTEXT_PROMPT, \\\n",
    "    RERANK_TRIPLETS_PROMPT, RERANK_CANDIDATE_ENTITIES_PROMPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToG pseudocode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = preprocess_text(\"Charles Dickens\")\n",
    "print(q)\n",
    "print(a)\n",
    "mid = mqa_graph.preprocessed_nodes.get(preprocess_text(entity))\n",
    "print(mid)\n",
    "entities = [mid]\n",
    "\n",
    "explored_entities = set(entities)\n",
    "P = [\n",
    "    # [step]: [triplet1, ...], \n",
    "    [(\"_\", mqa_graph.preprocessed_nodes[e])] for e in entities\n",
    "] # max_depth X beam_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for depth in range(max_depth):\n",
    "    tail_entities = set()\n",
    "    for t in P[depth-1]:\n",
    "        tail_entities.add(t[-1])\n",
    "    # get the unvisited ones\n",
    "    unexplored_entities = tail_entities.difference(explored_entities)\n",
    "    # add them as visited (for next iteration)\n",
    "    explored_entities.update(unexplored_entities)\n",
    "\n",
    "    edge_heap = []\n",
    "    # predict and rerank edges\n",
    "    for entity_mid in tail_entities:\n",
    "        entity = mqa_graph.mid2name[entity_mid]\n",
    "        # ??? potentially get all prev entities for that chain\n",
    "        predicted_edges = predict_n_edges(\n",
    "            question, [entity], #n=5\n",
    "        )\n",
    "        top_edges = rerank_edges_from_predicted(\n",
    "            node, predicted_edges, #n=5\n",
    "        ) # sorted in desc\n",
    "        # rebalance edge heap\n",
    "        for score, edge in top_edges:\n",
    "            heapq.heappush(edge_heap, (score, entity_mid edge))\n",
    "    # predict and rank tail entities\n",
    "    triplet_heap = []\n",
    "    for edge_score, entity_mid, edge in heapq.nlargest(5, edge_heap):\n",
    "        candidates_tails = []\n",
    "        top_tails = [candidate_tails]\n",
    "\n",
    "    # construct paths\n",
    "\n",
    "    # Reasoning\n",
    "        mid_rels = set(map(\n",
    "            lambda edge: edge[2][\"relation\"],\n",
    "            mqa_graph._graph.edges(entity_mid, data=True)\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 5, 4, 3]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 5, 1, 2, 9, 3, 4]\n",
    "h = []\n",
    "for i in a:\n",
    "    heapq.heappush(h, i)\n",
    "heapq.nlargest(4, h)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
