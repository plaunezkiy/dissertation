{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "# set to \"cuda:1\" for running in parallel on both GPUs\n",
    "device = torch.device(\"cuda:1\")\n",
    "torch.cuda.set_device(device)\n",
    "torch.set_default_device(device)\n",
    "import Stemmer\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from utils.graph import KGraphPreproc\n",
    "from utils.graph.chain import GraphChain\n",
    "from utils.llm.mistral import MistralLLM\n",
    "from utils.prompt import GRAPH_QA_PROMPT, ENTITY_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(prompt):\n",
    "    # global chain\n",
    "    # del mistral\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    r = chain.invoke(prompt)\n",
    "    return r[\"result\"]\n",
    "\n",
    "\n",
    "def save_results(fpath, data_rows):\n",
    "    with open(fpath, \"w\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"Model\"])\n",
    "        for r in data_rows:\n",
    "            writer.writerow([str(r)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral = MistralLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaqa_graph = KGraphPreproc.get_metaqa_graph()\n",
    "\n",
    "chain = GraphChain.from_llm(\n",
    "    llm=mistral,\n",
    "    graph=metaqa_graph,\n",
    "    qa_prompt=GRAPH_QA_PROMPT,\n",
    "    entity_prompt=ENTITY_PROMPT,\n",
    "    verbose=False,\n",
    ")\n",
    "chain.sbert_cache_path = \"/datasets/MetaQA/cache/sbert.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3hop\n",
      "depth: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 3735/14274 [5:51:38<125:28:43, 42.86s/it]"
     ]
    }
   ],
   "source": [
    "for hop in [\"3hop\"]:\n",
    "    print(hop)\n",
    "    # load q's\n",
    "    metaqa = pd.read_csv(f\"/datasets/MetaQA/{hop}/qa_test.txt\", sep=\"\\t\", header=None)\n",
    "    metaqa.rename(columns={0: \"Question\", 1: \"Answers\"}, inplace=True)\n",
    "\n",
    "\n",
    "    for depth in [3]:\n",
    "        print(f\"depth: {depth}\")\n",
    "        # set the depth\n",
    "        chain.exploration_depth = depth\n",
    "        # init experiment\n",
    "        experiment_name = f\"sbert-kb{depth}\"\n",
    "        res_path = f\"/datasets/MetaQA/results/{hop}/{experiment_name}.csv\"\n",
    "        results = []\n",
    "        l = 0\n",
    "        # load if preinit'ed\n",
    "        if os.path.isfile(res_path):\n",
    "            r_df = pd.read_csv(res_path)\n",
    "            l = len(r_df)\n",
    "            results = list(r_df.Model.values)\n",
    "        # run through\n",
    "        for i, r in tqdm(list(metaqa.iterrows())):\n",
    "            if i < l:\n",
    "                continue\n",
    "            q = r.Question\n",
    "            response = get_response(q)\n",
    "            results.append(response)\n",
    "            # backup every 10 qs\n",
    "            if i % 10 == 0:\n",
    "                save_results(res_path, results)\n",
    "        save_results(res_path, results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
