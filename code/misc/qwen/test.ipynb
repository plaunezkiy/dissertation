{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "device = torch.device(\"cuda:1\")\n",
    "torch.cuda.set_device(device)\n",
    "torch.set_default_device(device)\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "from utils.graph import KGraphPreproc\n",
    "from utils.preprocessing import preprocess_text\n",
    "import networkx as nx\n",
    "os.environ[\"HF_HOME\"] = \"/models\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"/models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_cache():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "clear_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "model_path = \"/models/hub/models--Qwen--Qwen2.5-0.5B-Instruct/snapshots/7ae557604adf67be50417f59c2c2f167def9a775\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mqa = pd.read_csv(f\"/datasets/MetaQA/meta.csv\")\n",
    "mqa_graph = KGraphPreproc.get_metaqa_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mqa.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mqa[\"chain\"] = mqa.apply(\n",
    "    lambda r: nx.shortest_path(\n",
    "        mqa_graph._graph,\n",
    "        mqa_graph.name2mid[r[\"topic_entity\"]],\n",
    "        mqa_graph.preprocessed_nodes[r.Answer]\n",
    "    ),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                               1-1\n",
       "hop                                                1\n",
       "Question        [Joe Thomas] appears in which movies\n",
       "topic_entity                              Joe Thomas\n",
       "Answer                               the inbetween 2\n",
       "actual_hops                                        2\n",
       "chain                                 [20874, 20869]\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = mqa.iloc[1]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tails(node, edge):\n",
    "    tails = set()\n",
    "    for u,v,attrs in mqa_graph._graph.edges(node, data=True):\n",
    "        if attrs.get(\"relation\") == edge:\n",
    "            tails.add(v)\n",
    "    return tails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_candidates_per_chain(row):\n",
    "    max_cands = -1\n",
    "    for start, target in zip(row.chain, row.chain[1:]):\n",
    "        edge = mqa_graph._graph[start][target][\"relation\"]\n",
    "        num_cands = len(get_tails(start, edge))\n",
    "        if num_cands > max_cands:\n",
    "            max_cands = num_cands\n",
    "    return max_cands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mqa[\"max_tail_cands\"] = mqa.apply(\n",
    "    max_candidates_per_chain,\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    302514.000000\n",
       "mean        391.867252\n",
       "std        1095.544542\n",
       "min          -1.000000\n",
       "25%           9.000000\n",
       "50%          21.000000\n",
       "75%          42.000000\n",
       "max        4176.000000\n",
       "Name: max_tail_cands, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mqa[mqa[\"max_tail_cands\"] < 1000]\n",
    "mqa[\"max_tail_cands\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joe Thomas\n",
      "starred_actors\n",
      "['The Inbetweeners Movie', 'The Inbetweeners 2']\n"
     ]
    }
   ],
   "source": [
    "start = row.chain[0]\n",
    "target = row.chain[1]\n",
    "edge = mqa_graph._graph[start][target][\"relation\"]\n",
    "cand_tails = get_tails(start, edge)\n",
    "print(\n",
    "    mqa_graph.mid2name[start],\n",
    "    edge,\n",
    "    list(map(lambda t: mqa_graph.mid2name[t], cand_tails)),\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reranking problem\n",
    "*For now, the next best thing to do is to use the same embedding similarity algorithm, but this poses an issue as semantic similarity of the candidates and preceding part of the triplet tells us nothing about the relevance to the actual question (types of qs), it also is likely biased towards the training data* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tail prediction\n",
    "Given a question, a relation, and candidates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICT_EDGE_PROMPT = \"\"\"\n",
    "You are an expert in knowledge graphs and natural language understanding. Your task is to help explore relevant relationships from given topic entities that can aid in answering a question.\n",
    "Instructions:\n",
    "Input: You will be provided with a natural language question and a list of topic entities extracted from that question.\n",
    "Objective: Analyze the question to understand its context and what information might be needed to answer it. Then, generate a list of 5 candidate relationship labels (i.e., edge types) that could be used to navigate a knowledge graph starting from each entity.\n",
    "Requirements:\n",
    "Relevance: The candidate relationship labels must be pertinent to the context of the question.\n",
    "Conciseness: Provide a brief description (1–2 sentences) of why each relationship label might help answer the question.\n",
    "Format: Return your answer as a numbered list in the following format: 1. (Entity; Relationship label; Reason)\n",
    "Do not produce any other text.\n",
    "\n",
    "Question: “What awards has Albert Einstein received?”\n",
    "Topic Entities: Albert Einstein;\n",
    "Candidate relationship labels (2 items):\n",
    "1. (Albert Einstein; awardReceived; Connects a person to the awards they have received.)\n",
    "2. (Albert Einstein; honorificAward; Links individuals to awards given in honor of their achievements.)\n",
    "\n",
    "Question: “{question}”\n",
    "Topic Entities: {entities}\n",
    "Candidate relationship labels (5 items):\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"Which Dickens novel features the character 'Uriah Heep'?\"\n",
    "e = [\"Charles Dickens\", \"David_Copperfield-GB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_link_prompt = '''\n",
    "You are an expert in knowledge graphs and natural language understanding. Your task is to help explore relevant relationships from given topic entities that can aid in answering a question.\n",
    "Instructions:\n",
    "Input: You will be provided with a natural language question and a list of topic entities extracted from that question.\n",
    "Objective: Analyze the question to understand its context and what information might be needed to answer it. Then, generate a list of 5 candidate relationship labels (i.e., edge types) that could be used to navigate a knowledge graph starting from each entity.\n",
    "Requirements:\n",
    "Relevance: The candidate relationship labels must be pertinent to the context of the question.\n",
    "Conciseness: Provide a brief description (1–2 sentences) of why each relationship label might help answer the question.\n",
    "Format: Return your answer as a numbered list in the following format: 1. (Entity; Relationship label; Reason)\n",
    "Do not produce any other text.\n",
    "\n",
    "Question: “What awards has Albert Einstein received?”\n",
    "Topic Entities: Albert Einstein;\n",
    "Candidate relationship labels (2 items):\n",
    "1. (Albert Einstein; awardReceived; Connects a person to the awards they have received.)\n",
    "2. (Albert Einstein; honorificAward; Links individuals to awards given in honor of their achievements.)\n",
    "\n",
    "Question: “{question}”\n",
    "Topic Entities: {entities}\n",
    "Candidate relationship labels (5 items):\n",
    "'''.format(question=q, entities=\"; \".join(e[::-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "decompose_question_prompt = \"\"\"\n",
    "Given a question, decompose it into a potential reasoning chain that can be used to navigate the knowledge graph to find the answer.\n",
    "Output the list of potential relation names\n",
    "Question: {question}\n",
    "\"\"\".format(question=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_rel_answer(answer_string, group=0):\n",
    "    pattern = re.compile(\"\\d+\\.\\s*\\(([^;]+);\\s*([^;]+);\\s*(.+?)\\)\")\n",
    "    pos = 0\n",
    "    rels = []\n",
    "    while m := pattern.search(answer_string, pos):\n",
    "        pos = m.start() + 1\n",
    "        entity, rel, reason = m[group].split(\";\")\n",
    "        rels.append(rel.strip())\n",
    "        # if entity in entity_set:\n",
    "        #     scored_entities.append((entity, float(rank)))\n",
    "    return rels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bookTitle',\n",
       " 'authorName',\n",
       " 'locationOfBook',\n",
       " 'nationality',\n",
       " 'genre',\n",
       " 'occupation',\n",
       " 'birthPlace',\n",
       " 'publicationDate',\n",
       " 'deathDate',\n",
       " 'biography',\n",
       " 'biography']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_rel_answer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. (David_Copperfield-GB; bookTitle; Identifies the title of the book featuring Uriah Heep.)\n",
      "2. (Charles_Dickens; authorName; Establishes the author's name for reference purposes.)\n",
      "3. (Charles_Dickens; genreOfNovel; Specifies the genre of the book.)\n",
      "4. (Charles_Dickens; characterName; Identifies the character named Uriah Heep.)\n",
      "5. (Charles_Dickens; plotElement; Mentions the plot element of Uriah Heep being involved in\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(predict_link_prompt, return_tensors=\"pt\", return_attention_mask=False)\n",
    "\n",
    "outputs = model.generate(**inputs, max_length=400, temperature=0.15)\n",
    "text = tokenizer.batch_decode(outputs[:, inputs[\"input_ids\"].shape[1]:])[0]\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
