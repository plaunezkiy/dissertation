{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HOME\"] = \"/models\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"/models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\")\n",
    "torch.cuda.set_device(device)\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae42f72a9534c4c8220f74806b8aaed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f060f9f44e4e5aa07d3fd38c7e3f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\", torch_dtype=\"auto\", trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"Which Dickens novel features the character 'Uriah Heep'?\"\n",
    "e = \"Charles Dickens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''\n",
    "You are navigating a knowledge graph, where nodes are entities and edges are relationships between them.\n",
    "Given a question and and starting entity, predict 2 (semi-colon separated) potentially useful edge to explore.\n",
    "Output in the following format:\n",
    "1. (edge, (score)) reason\n",
    "Question: {question}\n",
    "Entity: {entity}\n",
    "Relationships: \n",
    "'''.format(question=q, entity=e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are navigating a knowledge graph, where nodes are entities and edges are relationships between them.\n",
      "Given a question and and starting entity, predict 2 (semi-colon separated) potentially useful edge to explore.\n",
      "Output in the following format:\n",
      "1. (edge, (score)) reason\n",
      "Question: Which Dickens novel features the character 'Uriah Heep'?\n",
      "Entity: Charles Dickens\n",
      "Relationships: \n",
      "1. (Uriah Heep, (Charles Dickens, (1812-1870))) reason\n",
      "2. (Uriah Heep, (Oliver Twist, (1838-1839))) reason\n",
      "3. (Uriah Heep, (Great Expectations, (1861-1862))) reason\n",
      "4. (Uriah Heep, (A Tale of Two Cities, (1859-1860))) reason\n",
      "5. (Uriah Heep, (Bleak House, (1853-1854))) reason\n",
      "6. (Uriah Heep, (Great Expectations, (1861-1862))) reason\n",
      "7. (Uriah Heep, (Oliver Twist, (1838-1839))) reason\n",
      "8. (Uriah Heep, (A Tale of Two Cities, (1859-1860))) reason\n",
      "9. (Uriah Heep, (Bleak House, (1853-1854))) reason\n",
      "10. (Uriah Heep, (Great Expectations, (1861-1862))) reason\n",
      "11. (Uriah Heep, (Oliver Twist, (1838-1839))) reason\n",
      "12. (Uriah Heep, (A Tale of Two Cities, (1859-1860))) reason\n",
      "13. (Uriah Heep, (Bleak House, (1853-1854))) reason\n",
      "14. (Uriah Heep, (Great Expectations, (1861-1862))) reason\n",
      "15. (Uriah Heep, (Oliver Twist, (1838-1839))) reason\n",
      "16. (Uriah Heep, (A Tale of Two Cities, (1859-1860))) reason\n",
      "17. (Uriah Heep, (Bleak House, (1853-1854))) reason\n",
      "18. (Uriah Heep, (Great Expectations, (1861-1862))) reason\n",
      "19. (Uriah Heep, (Oliver Twist, (1838-1839))) reason\n",
      "20. (Uriah Heep, (A Tale of Two Cities, (1859-1860))) reason\n",
      "21. (Uriah Heep, (Bleak House, (1853-1854))) reason\n",
      "22. (Uriah Heep, (Great Expectations, (1861-1862))) reason\n",
      "23. (Uriah Heep, (Oliver Twist, (1838-1839))) reason\n",
      "24. (Uriah Heep, (A Tale of Two Cities, (1859-1860))) reason\n",
      "25. (Uriah Heep, (Bleak House, (1853-1854))) reason\n",
      "26. (Uriah Heep, (Great Expectations, (1861-1862))) reason\n",
      "27. (Uriah Heep, (Oliver Twist, (1838-1839))) reason\n",
      "28. (Uriah Heep, (A Tale of Two Cities, (1859-1860))) reason\n",
      "29. (Uriah Heep, (Bleak House, (1853-1854))) reason\n",
      "30. (Uriah Heep, (Great Expectations, (1861-1862))) reason\n",
      "31. (Uriah Heep, (Oliver Twist, (1838-1839))) reason\n",
      "32. (Uriah Heep, (A Tale of Two Cities, (1859-1860))) reason\n",
      "33. (Uriah Heep, (Bleak House, (1853-1854))) reason\n",
      "34. (Uriah Heep, (Great Expectations, (1861-1862))) reason\n",
      "35. (Uriah Heep, (Oliver Twist, (1838-1839))) reason\n",
      "36. (Uriah Heep, (A Tale of Two Cities, (1859-1860))) reason\n",
      "37. (Uriah Heep, (Bleak House, (1853-1854))) reason\n",
      "38. (Uriah Heep, (Great Expectations, (1861-1862))) reason\n",
      "39. (Uriah Heep, (Oliver Twist, (1838-1839))) reason\n",
      "40. (Uriah Heep, (A Tale of Two Cities, (1859-1860))) reason\n",
      "41. (Uriah Heep, (Bleak House, (1853-1854))) reason\n",
      "42. (Uriah Heep, (Great Expectations, (1861-1862))) reason\n",
      "43. (Uriah Heep, (Oliver Twist, (1838-1839))) reason\n",
      "44. (Uriah Heep, (A Tale of Two Cities, (1859-1860))) reason\n",
      "45. (Uriah Heep, (Bleak House, (1853-1854))) reason\n",
      "46. (Uriah Heep, (Great Expectations, (1861-1862))) reason\n",
      "47. (Uriah Heep, (Oliver Twist, (1838-1839))) reason\n",
      "48. (Uriah Heep, (A Tale of Two Cities, (1859-1860))) reason\n",
      "49. (Uriah Heep, (Bleak House, (1853-1854))) reason\n",
      "50. (Uriah Heep, (Great Expectations, (1861-1862))) reason\n",
      "\n",
      "A:\n",
      "\n",
      "You can use a breadth-first search to find the shortest path from the starting entity to the target entity.\n",
      "Here's a Python implementation:\n",
      "from collections import deque\n",
      "\n",
      "def shortest_path(graph, start, target):\n",
      "    queue = deque([(start, [start])])\n",
      "    visited = set()\n",
      "    while queue:\n",
      "        node, path = queue.popleft()\n",
      "        if node == target:\n",
      "            return path\n",
      "        if node not in visited:\n",
      "            visited.add(node)\n",
      "            for neighbor in graph[node]:\n",
      "                queue.append((neighbor, path + [neighbor]))\n",
      "    return None\n",
      "\n",
      "graph = {\n",
      "    'Charles Dickens': ['Uriah Heep', 'Oliver Twist', 'Great Expectations', 'A Tale of Two Cities', 'Bleak House'],\n",
      "    'Uriah Heep': ['Charles Dickens', 'Oliver Twist', 'Great Expectations', 'A Tale of Two Cities', 'Bleak House'],\n",
      "    'Oliver Twist': ['Charles Dickens', 'Uriah Heep', 'Great Expectations', 'A Tale of Two Cities', 'Bleak House'],\n",
      "    'Great Expectations': ['Charles Dickens', 'Uriah Heep', 'Oliver Twist', 'A Tale of Two Cities', 'Bleak House'],\n",
      "    'A Tale of Two Cities': ['Charles Dickens', 'Uriah Heep', 'Oliver Twist', 'Great Expectations', 'Bleak House'],\n",
      "    'Bleak House': ['Charles Dickens', 'Uriah Heep', 'Oliver Twist', 'Great Expectations', 'A Tale of Two Cities']\n",
      "}\n",
      "\n",
      "print(shortest_path(graph, 'Charles Dickens', 'Uriah Heep'))\n",
      "# Output: ['Charles Dickens', 'Uriah Heep']\n",
      "\n",
      "print(shortest_path(graph, 'Charles Dickens', 'Oliver Twist'))\n",
      "# Output: ['Charles Dickens', 'Uriah Heep', 'Oliver Twist']\n",
      "\n",
      "print(shortest_path(graph, 'Charles Dickens', 'Great Expectations'))\n",
      "# Output: ['Charles Dickens', 'Uriah Heep', 'Oliver Twist', 'Great Expectations']\n",
      "\n",
      "print(shortest_path(graph, 'Charles Dickens', 'A Tale of Two Cities'))\n",
      "# Output: ['Charles Dickens', 'Uriah Heep', 'Oliver Twist', 'Great Expectations', 'A Tale of Two Cities']\n",
      "\n",
      "print(shortest_path(graph, 'Charles Dickens', 'Bleak House'))\n",
      "# Output: ['Charles Dickens', 'Uriah Heep', 'Oliver Twist', 'Great Expectations', 'A Tale of Two Cities', 'Bleak House']\n",
      "\n",
      "print(shortest_path(graph, 'Charles Dickens', 'Uriah Heep', max_depth=2))\n",
      "# Output: ['Charles Dickens', 'Uriah Heep']\n",
      "\n",
      "print(shortest_path(graph, 'Charles Dickens', 'Oliver Twist', max_depth=2))\n",
      "# Output: ['Charles Dickens', 'Uriah Heep', 'Oliver Twist']\n",
      "\n",
      "print(shortest_path(graph, 'Charles Dickens', 'Great Expectations', max_depth=2))\n",
      "# Output: ['Charles Dickens', 'Uriah Heep', 'Oliver Twist', 'Great Expectations']\n",
      "\n",
      "print(shortest_path(graph, 'Charles Dickens', 'A Tale of Two Cities', max_depth=2))\n",
      "# Output: ['Charles Dickens', '\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\", return_attention_mask=False)\n",
    "\n",
    "outputs = model.generate(**inputs, max_length=2048)\n",
    "text = tokenizer.batch_decode(outputs)[0]\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
