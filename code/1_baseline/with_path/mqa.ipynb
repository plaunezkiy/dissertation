{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# set to \"cuda:1\" for running in parallel on both GPUs\n",
    "device = torch.device(\"cuda:1\")\n",
    "torch.cuda.set_device(device)\n",
    "torch.set_default_device(device)\n",
    "import pandas as pd\n",
    "from utils.graph import KGraphPreproc\n",
    "from utils.llm.mistral import MistralLLM\n",
    "from utils.prompt import GRAPH_QA_PROMPT\n",
    "from tqdm import tqdm\n",
    "from utils.file import export_results_to_file\n",
    "import os\n",
    "import networkx as nx\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral = MistralLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mqa_graph = KGraphPreproc.get_metaqa_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplet_path(graph, start, target):\n",
    "    try:\n",
    "        path = nx.shortest_path(graph._graph, start, target)\n",
    "        triplets = []\n",
    "        for s,t in zip(path, path[1:]):\n",
    "            head = graph.mid2name.get(s, None)\n",
    "            rel = graph._graph[s][t].get(\"relation\", None)\n",
    "            tail = graph.mid2name.get(t, None)\n",
    "            triplets.append(f'{head}-{rel}-{tail}')\n",
    "        return triplets\n",
    "    except (nx.NetworkXNoPath, nx.NodeNotFound):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "regex_mqa_topic_entity = re.compile(\"\\[(.*?)\\]\")\n",
    "def extract_mqa_topic_entity(question):\n",
    "    mid = regex_mqa_topic_entity.findall(question)[0]\n",
    "    return mqa_graph.name2mid.get(mid, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hops: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1785570.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hops: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [08:34<00:00,  1.94it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hops: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [40:50<00:00,  2.45s/it] \n"
     ]
    }
   ],
   "source": [
    "# init experiment\n",
    "for hop in [1,2,3]:\n",
    "    print(f\"Hops: {hop}\")\n",
    "    experiment_name = f\"kb-path\"\n",
    "    res_path = f\"/datasets/MetaQA/results/{hop}hop/{experiment_name}.csv\"\n",
    "    results = []\n",
    "    id_list = []\n",
    "    l = 0\n",
    "    # load if preinit'ed\n",
    "    if os.path.isfile(res_path):\n",
    "        r_df = pd.read_csv(res_path)\n",
    "        l = len(r_df)\n",
    "        results = list(r_df.Model.values)\n",
    "    # run through\n",
    "    metaqa = metaqa = pd.read_csv(f\"/datasets/MetaQA/{hop}hop/test_1000.txt\", header=None, index_col=0)\n",
    "    metaqa.rename(columns={1: \"Question\", 2: \"Answers\"}, inplace=True)\n",
    "    for c, (i, r) in enumerate(tqdm(list(metaqa.iterrows()))):\n",
    "        id_list.append(i)\n",
    "        if c < l:\n",
    "            continue\n",
    "        topic_ids = [extract_mqa_topic_entity(r.Question)]\n",
    "        answer_ids = list(map(mqa_graph.name2mid.get, r.Answers.split(\"|\")))\n",
    "\n",
    "        paths = [\n",
    "            [start, target] for start in topic_ids for target in answer_ids\n",
    "        ]\n",
    "        context = []\n",
    "        for pair in paths:\n",
    "            context.extend(get_triplet_path(mqa_graph, *pair))\n",
    "        prompt = GRAPH_QA_PROMPT.format(\n",
    "            context=\";\".join(context),\n",
    "            question=r.Question\n",
    "        )\n",
    "        response = mistral.get_response(prompt)\n",
    "        results.append(response)\n",
    "        # backup every 10 qs\n",
    "        if c % 10 == 0:\n",
    "            export_results_to_file(res_path, results, id_list)\n",
    "    export_results_to_file(res_path, results, id_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
